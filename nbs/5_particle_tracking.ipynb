{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115405e9",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td><p style=\"font-size:45px; color: #55BBD2\">Analysis of light microscopy images in Python</p></td>\n",
    "    <td><img src=\"../ressources/lmb_logo.svg\" alt=\"LMB Logo\" width=\"500\" height=\"600\" align=\"right\"></td>\n",
    "  </tr>\n",
    "</table>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><p style=\"font-size:15px; color: #55BBD2\">Version: September 2025</p></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cda60ad",
   "metadata": {},
   "source": [
    "# Part 5: Particle tracking\n",
    "\n",
    "<b>Problem:</b> Track transcription factor CDX2\n",
    "\n",
    "<b>Dataset:</b> 181228_CDX2_9s_c48_n073.tif\n",
    "\n",
    "<b>Credit:</b> Kuhn, Timo; Hettich, Johannes; Davtyan, Rubina; Gebhardt, J. Christof M. (2021), Single molecule tracking and analysis framework including theory-predicted parameter settings, Scientific Reports, Journal-article, [https://doi.org/10.1038/s41598-021-88802-7](https://doi.org/10.1038/s41598-021-88802-7). [Link to dataset](https://datadryad.org/dataset/doi:10.5061/dryad.0zpc866wh).\n",
    "\n",
    "<b>Objectives:</b>\n",
    "- Detect particles (skimage.feature.blob_dog)\n",
    "- Join dataframes (pandas.concat, pandas.merge, pandas.DataFrame.groupby)\n",
    "- Track particles by linking their positions over time (laptrack.LapTrack)\n",
    "- Visualize tracks and 3D rendering using napari (napari.add_tracks)\n",
    "\n",
    "<b>Workflow:</b>\n",
    "\n",
    "<img src=\"../ressources/workflow/workflow3.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1eb578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from bioio import BioImage\n",
    "\n",
    "data_folder = Path('../data')\n",
    "particles = BioImage(data_folder / '181228_CDX2_9s_c48_n073.tif')\n",
    "particles_data = particles.data\n",
    "\n",
    "sz = particles_data.shape\n",
    "print(sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d33083",
   "metadata": {},
   "source": [
    "## Napari display\n",
    "Now we are going to display the particles images, consisting of 105 frames, using the napari plugin. To be able to visualize the 3D rendering of the data, we need to ensure we are displaying a 3D image in one layer. In other words, we need to specify the channel and z = 0 in the viewer i.e display particles_data[:, 0, 0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda5d1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "\n",
    "v = napari.Viewer()\n",
    "v.add_image(particles_data[:, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453e7990",
   "metadata": {},
   "source": [
    "## Detect each particle (spot) using blob_dog from the feature module\n",
    "\n",
    "The blob_dog is another function for spot detection. It is a faster approximation of the LoG approach and has few parameters that we need to care for in order to filter out what we consider particles and which ones are not. There are importants parameters that we will cover here: threshold, min_sigma and max_sigma. \n",
    "\n",
    "- threshold: The absolute lower bound for scale space maxima. Local maxima smaller than threshold are ignored. Reduce this to detect blobs with lower intensities. <br>\n",
    "- min_sigma: The minimum standard deviation for Gaussian kernel.\n",
    "- max_sigma: The maximum standard deviation for Gaussian kernel.\n",
    "\n",
    "Further reading: https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.blob_dog\n",
    "\n",
    "We will save the positions of the detected particles in a panda dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88328a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature \n",
    "import pandas as pd\n",
    "\n",
    "particles_positions = []\n",
    "\n",
    "for t in range(sz[0]):    \n",
    "    coordinates = feature.blob_dog(particles_data[t].squeeze(), min_sigma=1, max_sigma=5, threshold=0.005)    \n",
    "    particles_positions.append(pd.DataFrame({'x': coordinates[:,1], 'y': coordinates[:,0], 'w': coordinates[:,2], 'frame':t}))\n",
    "\n",
    "particles_positions = pd.concat(particles_positions)\n",
    "    \n",
    "particles_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b688748f",
   "metadata": {},
   "source": [
    "We do not have tracks yet here but points. We can use add_points to add the points to the napari viewer. We will need to select the dataframe from the the TYX information, where T is the timepoints or frames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5056ea25",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "       \n",
    "#### Exercise \n",
    "\n",
    "Add the points to the napari viewer using particles_positions[['frame', 'y', 'x']]. Set the size to 1, opacity to 0.5, and face_color to 'green'.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d1f674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b45cb312",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "#### Exercise       \n",
    "\n",
    "The results we have here were optimized using threshold = 0.005, min_sigma = 1, and max_sigma = 5. You may find a better setting than these. <br> \n",
    "So go back to the spot detection cell and play with the values of those three parameters and observe how the results are changing accordingly.\n",
    "\n",
    "   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a835aeb",
   "metadata": {},
   "source": [
    "## Particles trajectories\n",
    "We are now going to trace the trajectories of the particles by linking the coordinates positions. <br> \n",
    "For this, we will use a Python package named 'laptrack'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781d511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from laptrack import LapTrack\n",
    "\n",
    "lt = LapTrack(cutoff=5**2)\n",
    "track_df, _, _ = lt.predict_dataframe(particles_positions, [\"y\", \"x\"], only_coordinate_cols=False)\n",
    "track_df = track_df.reset_index()\n",
    "\n",
    "v.add_tracks(track_df[[\"track_id\", \"frame\", \"y\", \"x\"]], tail_length=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a510695",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "#### Exercise       \n",
    "\n",
    "Laptrack has a hands-on list of parameters that we can tune to improve the tracking results. The essential parameters are listed below. Play with those to understand how it works.\n",
    "   \n",
    "- \"dist_metric\": the global metric to use to calculate any distance. Default value is \"sqeuclidean\". With this, any input distance should be squared distance. For \"euclidean\", the distance is used not its square.\n",
    "\n",
    "- \"cutoff\" or \"track_cost_cutoff\": maximum allowed distance between particles to form a track.\n",
    "\n",
    "- \"gap_closing_cost_cutoff\": cost cutoff for gap closing i.e linking one track to another. It is the maximum allowed distance between last frame of one track and the start of the another track to link the two tracks as one.\n",
    "\n",
    "- \"gap_closing_max_frame_count\": maximum frame gaps\n",
    "\n",
    "Further reading: [here](https://laptrack.readthedocs.io/en/stable/reference.html)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d723fc",
   "metadata": {},
   "source": [
    "## Additional constraints\n",
    "\n",
    "But maybe we eventually want to remove particles that are only appearing in few frames?\n",
    "\n",
    "Let say we won't consider the trajectories of particles that are appearing in less than 10 frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04fd9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "allowed_track_length = 10\n",
    "\n",
    "# initialize the selected_tracks dataframe\n",
    "selected_tracks = pd.DataFrame([])\n",
    "\n",
    "for id, df in track_df.groupby(\"track_id\"):     # group the dataframe in terms of \"track_id\"\n",
    "    if len(df) >= allowed_track_length:         # apply the desired condition using the if statement\n",
    "        selected_tracks = pd.concat([selected_tracks, df], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c04aaa2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "#### Exercise       \n",
    "\n",
    "Change the allowed_track_length and observe the number of trajectories displayed in the overlay display. Use add_tracks to add the selected_tracks on the napari viewer.\n",
    "   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5793b969",
   "metadata": {},
   "source": [
    "## Exporting tabular results\n",
    "\n",
    "To save results in a csv file use the export function from pandas. <br>\n",
    "The excelsheet will be save in your current directory. To check where is that directory, run the command pwd in a new cell and you will see the csv file be saved in that directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42be1e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecbfac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_tracks.to_csv('tracking_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83796f9b",
   "metadata": {},
   "source": [
    "# Some more helpful tips\n",
    "\n",
    "- scientific images are data, they can be compromised by inappropriate manipulations\n",
    "- take good images:\n",
    "    - don't oversaturate your data\n",
    "    - use the full dynamic range when taking your images\n",
    "- do not segment on the data you are measuring, use a housekeeping channel\n",
    "- images that are compared to each other need to be processed and acquired in the same manner"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dynamicIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
