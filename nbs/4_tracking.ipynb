{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "115405e9",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td><p style=\"font-size:45px; color: #55BBD2\">Analysis of light microscopy images in Python</p></td>\n",
    "    <td><img src=\"../ressources/lmb_logo.svg\" alt=\"LMB Logo\" width=\"500\" height=\"600\" align=\"right\"></td>\n",
    "  </tr>\n",
    "</table>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><p style=\"font-size:15px; color: #55BBD2\">Version: September 2025</p></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cda60ad",
   "metadata": {},
   "source": [
    "# Part 3: Particle tracking\n",
    "\n",
    "<b>Problem:</b> Track transcription factor CDX2\n",
    "\n",
    "<b>Dataset:</b> 181228_CDX2_9s_c48_n073.tif\n",
    "\n",
    "<b>Credit:</b> Kuhn, Timo; Hettich, Johannes; Davtyan, Rubina; Gebhardt, J. Christof M. (2021), Single molecule tracking and analysis framework including theory-predicted parameter settings, Scientific Reports, Journal-article, [https://doi.org/10.1038/s41598-021-88802-7](https://doi.org/10.1038/s41598-021-88802-7). [Link to dataset](https://datadryad.org/dataset/doi:10.5061/dryad.0zpc866wh).\n",
    "\n",
    "<b>Objectives:</b>\n",
    "- Filter an image (skimage.filters.gaussian, skimage.filters.median)\n",
    "- Segment an image using a simple thresholding (comparison operators >=, skimage.filters.threshold_otsu)\n",
    "- Visualize segmentation results (skimage.measure.find_contours)\n",
    "- Post process binary masks (skimage.morphology.remove_small_objects, skimage.morphology.closing, morphology.footprint_rectangle, skimage.segmentation.clear_border, skimage.color.label2rgb, scipy.ndimage.binary_fill_holes)\n",
    "- Segment overlapping objects using a watershed-based segmentation (scipy.ndimage.distance_transform_edt, skimage.segmentation.watershed)\n",
    "- Convert the bit depth of an image (numpy.ndarray.astype)\n",
    "- Detect spots and generate an image of spot labels from the coordinates (skimage.feature.blob_dog, skimage.util.label_points)\n",
    "- Measure information within a given ROI (skimage.measure.regionprops_table)\n",
    "- Use object parenting to count spots per cell (the def keyword)\n",
    "- Manipulate and structure tabular data (pandas.DataFrame, pandas.merge, pandas.DataFrame.to_csv)\n",
    "\n",
    "<b>Workflow:</b>\n",
    "\n",
    "<img src=\"../ressources/workflow/workflow3.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1eb578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from bioio import BioImage\n",
    "\n",
    "data_folder = Path('../data')\n",
    "particles = BioImage(Path(data_folder, '181228_CDX2_9s_c48_n073.tif'))\n",
    "particles_data = particles.data\n",
    "\n",
    "sz = particles_data.shape\n",
    "print(sz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d33083",
   "metadata": {},
   "source": [
    "## Napari display\n",
    "Now we are going to display the particles images, consisting of 105 frames, using the napari plugin. To be able to visualize the 3D rendering of the data, we need to ensure we are displaying a 3D image in one layer. In other words, we need to specify the channel and z = 0 in the viewer i.e display particles_data[:,0,0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda5d1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "\n",
    "v = napari.Viewer()\n",
    "v.add_image(particles_data[:,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453e7990",
   "metadata": {},
   "source": [
    "## Detect each particle (spot) using blob_dog from the feature module\n",
    "\n",
    "The blob_dog is another function for spot detection. It is a faster approximation of the LoG approach and has few parameters that we need to care for in order to filter out what we consider particles and which ones are not. There are importants parameters that we will cover here: threshold, min_sigma and max_sigma. \n",
    "\n",
    "- threshold: The absolute lower bound for scale space maxima. Local maxima smaller than threshold are ignored. Reduce this to detect blobs with lower intensities. <br>\n",
    "- min_sigma: The minimum standard deviation for Gaussian kernel.\n",
    "- max_sigma: The maximum standard deviation for Gaussian kernel.\n",
    "\n",
    "Further reading: https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.blob_dog\n",
    "\n",
    "We will save the positions of the detected particles in a panda dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88328a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature \n",
    "import pandas as pd\n",
    "\n",
    "particles_positions = []\n",
    "\n",
    "for t in range(sz[0]):    \n",
    "    coordinates = feature.blob_dog(particles_data[t].squeeze(), min_sigma=1, max_sigma=5, threshold=0.005)    \n",
    "    particles_positions.append(pd.DataFrame({'x': coordinates[:,1], 'y': coordinates[:,0], 'w': coordinates[:,2], 'frame':t}))\n",
    "\n",
    "particles_positions = pd.concat(particles_positions)\n",
    "    \n",
    "particles_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b688748f",
   "metadata": {},
   "source": [
    "We do not have tracks yet here but points. We can use add_points to add the points to the napari viewer. We will need to select the dataframe from the the TYX information, where T is the timepoints or frames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5056ea25",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "       \n",
    "#### Exercise \n",
    "\n",
    "Add the points to the napari viewer using particles_positions[['frame', 'y', 'x']]. Set the size to 1, opacity to 0.5, and face_color to 'green'.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d1f674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b45cb312",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "#### Exercise       \n",
    "\n",
    "The results we have here were optimized using threshold = 0.005, min_sigma = 1, and max_sigma = 5. You may find a better setting than these. <br> \n",
    "So go back to the spot detection cell and play with the values of those three parameters and observe how the results are changing accordingly.\n",
    "\n",
    "   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a835aeb",
   "metadata": {},
   "source": [
    "## Particles trajectories\n",
    "We are now going to trace the trajectories of the particles by linking the coordinates positions. <br> \n",
    "For this, we will use a Python package named 'laptrack'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781d511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from laptrack import LapTrack\n",
    "\n",
    "lt = LapTrack(cutoff=5**2)\n",
    "track_df, _, _ = lt.predict_dataframe(particles_positions, [\"y\", \"x\"], only_coordinate_cols=False)\n",
    "track_df = track_df.reset_index()\n",
    "\n",
    "v.add_tracks(track_df[[\"track_id\", \"frame\", \"y\", \"x\"]], tail_length=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a510695",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "#### Exercise       \n",
    "\n",
    "Laptrack has a hands-on list of parameters that we can tune to improve the tracking results. Check them [here](https://laptrack.readthedocs.io/en/stable/reference.html) and play with the parameters to understand how it works.\n",
    "   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d723fc",
   "metadata": {},
   "source": [
    "## Additional constraints\n",
    "\n",
    "But maybe we eventually want to remove particles that are only appearing in few frames?\n",
    "\n",
    "Let say we won't consider the trajectories of particles that are appearing in less than 10 frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a207bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "l = track_df['track_id'].unique() \n",
    "allowed_track_length = 10\n",
    "particles_id = [k for k in l if len(track_df.loc[track_df['track_id']==k])>=allowed_track_length]\n",
    "\n",
    "selected_tracks = pd.DataFrame([])\n",
    "\n",
    "for t in range(len(particles_id)):\n",
    "    coordinates = track_df.loc[track_df['track_id']==particles_id[t]]\n",
    "    selected_tracks = pd.concat([selected_tracks, coordinates])\n",
    "\n",
    "selected_tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c04aaa2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "#### Exercise       \n",
    "\n",
    "Change the allowed_track_length and observe the number of trajectories displayed in the overlay display.\n",
    "   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5793b969",
   "metadata": {},
   "source": [
    "## Exporting tabular results\n",
    "\n",
    "To save results in a csv file use the export function from pandas. <br>\n",
    "The excelsheet will be save in your current directory. To check where is that directory, run the command pwd in a new cell and you will see the csv file be saved in that directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42be1e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecbfac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_tracks.to_csv('tracking_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83796f9b",
   "metadata": {},
   "source": [
    "# Some more helpful tips\n",
    "\n",
    "- scientific images are data, they can be compromised by inappropriate manipulations\n",
    "- take good images:\n",
    "    - don't oversaturate your data\n",
    "    - use the full dynamic range when taking your images\n",
    "- do not segment on the data you are measuring, use a housekeeping channel\n",
    "- images that are compared to each other need to be processed and acquired in the same manner"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imaging-python-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
