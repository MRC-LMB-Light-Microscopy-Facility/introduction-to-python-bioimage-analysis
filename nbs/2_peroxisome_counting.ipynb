{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf125fcf",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td><p style=\"font-size:45px; color: #55BBD2\">Analysis of light microscopy images in Python</p></td>\n",
    "    <td><img src=\"../ressources/lmb_logo.svg\" alt=\"LMB Logo\" width=\"500\" height=\"600\" align=\"right\"></td>\n",
    "  </tr>\n",
    "</table>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><p style=\"font-size:15px; color: #55BBD2\">Version: September 2025</p></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f063a083",
   "metadata": {},
   "source": [
    "# Part 2: Measurement in a region of interest (ROI)\n",
    "\n",
    "<b>Problem:</b> Count the number of peroxisome in a cell\n",
    "\n",
    "<b>Dataset:</b> airyscan-4colors.tif\n",
    "\n",
    "![title](../ressources/data1.png)\n",
    "\n",
    "<b>Credit:</b> Ulrike Schulze\n",
    "\n",
    "<b>Objectives:</b>\n",
    "- Filter an image (skimage.filters.gaussian, skimage.filters.median)\n",
    "- Segment an image using a simple thresholding (comparison operators >=, skimage.filters.threshold_otsu)\n",
    "- Visualize segmentation results (skimage.measure.find_contours)\n",
    "- Post process binary masks (skimage.morphology.remove_small_objects, skimage.morphology.closing, morphology.footprint_rectangle, skimage.segmentation.clear_border, skimage.color.label2rgb, scipy.ndimage.binary_fill_holes)\n",
    "- Segment overlapping objects using a watershed-based segmentation (scipy.ndimage.distance_transform_edt, skimage.segmentation.watershed)\n",
    "- Convert the bit depth of an image (numpy.ndarray.astype)\n",
    "- Detect spots and generate an image of spot labels from the coordinates (skimage.feature.blob_dog, skimage.util.label_points)\n",
    "- Measure information within a given ROI (skimage.measure.regionprops_table)\n",
    "- Use object parenting to count spots per cell (the def keyword)\n",
    "- Manipulate and structure tabular data (pandas.DataFrame, pandas.merge, pandas.DataFrame.to_csv)\n",
    "\n",
    "<b>Workflow:</b>\n",
    "\n",
    "<img src=\"../ressources/workflow/workflow1.png\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc36502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from bioio import BioImage\n",
    "\n",
    "data_folder = Path('../data')\n",
    "image = BioImage(data_folder /'airyscan-4colors.tif')\n",
    "\n",
    "data = image.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e7d053",
   "metadata": {},
   "source": [
    "## Image filtering and noise\n",
    "Filtering is a technique for modifying or enhancing an image. We can filter an image to emphasize certain features or remove other features. Noise filtering is an example of image filtering. Noise in microscopic image is unavoidable during image acquisition. Dominant noise in fluorescence microscopy follows either a Gaussian distribution or Poisson distribution or both but mostly both. Gaussian noise is additive while Poisson noise is signal dependent.\n",
    "\n",
    "### Noise filtering\n",
    "\n",
    "There are different types of noise reduction such as smoothing filtering or convolution filtering, median filtering, or frequency filtering. \n",
    "\n",
    "As each pixel has a value which represents the image intensity at the spatial position of the pixel, we need to work on each pixel of the image to filter an image.\n",
    "\n",
    "### Gaussian filter\n",
    "A smoothing filter can use the principle of convolution to reduce the noise. The process is similar to drawing where the kernel is the pencil. The sharpness of the drawn image depends on the width of the point of the pencil. In the case of a Gaussian filtering, the Gaussian distribution is used as a kernel. When used for noise filtering, the noise, which should have a lower intensity value than the real signal, gets smoothed out because of this convolution process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6941866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Crop the image and select the first channel\n",
    "crop = image.data[0, 0, 0, 850:950, 900:1000]\n",
    "\n",
    "# Gaussian filtering of data with a Gaussian filter of a given sigma\n",
    "sigma = 3\n",
    "gaussian_filtered = filters.gaussian(crop.astype(float), sigma)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "vmin, vmax = crop.min(), crop.max()\n",
    "\n",
    "axs[0].imshow(crop, vmin = vmin, vmax = vmax)                      # original image\n",
    "axs[0].set_title('Noisy image')\n",
    "axs[0].set_axis_off()\n",
    "\n",
    "axs[1].imshow(gaussian_filtered, vmin = vmin, vmax = vmax)                # Gaussian filtered\n",
    "axs[1].set_title(r'Gaussian filtered ($\\sigma=$'+str(sigma)+')')\n",
    "axs[1].set_axis_off()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c46b06",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "       \n",
    "#### Exercise \n",
    "\n",
    "In the previous cell, change the standard deviation sigma of the Gaussian kernel and observe the change in the Gaussian filtered image.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf819c1b",
   "metadata": {},
   "source": [
    "### Median filter\n",
    "\n",
    "Median filtering is a different noise filtering technique. With the median filter, each output pixel is computed as the median value of the input pixel under a chosen window called footprint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b6f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "import numpy as np\n",
    "\n",
    "# define the footprint\n",
    "footprint = np.ones((5,5)) \n",
    "\n",
    "# the footprint is introduced in the second argument of the function \n",
    "median_filtered = filters.median(crop, footprint) \n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "# compute the min and max of the original image to keep the same display range\n",
    "vmin, vmax = crop.min(), crop.max()\n",
    "\n",
    "axs[0].imshow(crop, vmin = vmin, vmax = vmax)    \n",
    "axs[0].set_title('Noisy image')\n",
    "axs[0].set_axis_off()\n",
    "\n",
    "axs[1].imshow(median_filtered,  vmin = vmin, vmax = vmax)    \n",
    "axs[1].set_title('Median filtered')\n",
    "axs[1].set_axis_off()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2860fc19",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "#### Exercise       \n",
    "\n",
    "Change the size of the footprint and observe the change in the median filtered image.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f07bc81",
   "metadata": {},
   "source": [
    "## Segmentation\n",
    "\n",
    "Image segmentation is the process of partitioning an image into multiple distinct regions. In semantic segmentation, regions can represent objects of interests against background. They can then be represented as a binary mask. Several type of objects can be further encoded using a label image. Finally, instance segmentation aims at distinguishing different identities of objects of potentially the same class and can also be represented using a label image.\n",
    "\n",
    "To segment, we need to find the masks which represent each region of interest (ROI). This can easily be done by simply thresholding the intensity of the image. By this, the mask is defined such that only intensity (pixel) values greater than the threshold are selected. If we stop at this stage, we may encounter a problem such that some values within the thresholded region may get discarded because the intensity value is lower than the threshold and the ROI won't be filled. In this case, we may need to find the edge or/and fill the mask region. Another issue that we may encounter is that the edges of the regions may overlap so they may be detected or segmented as one. One solution in this case is to use what is called watershed segmentation. This technique helps to detect the flow of the intensity and decide from there whether the regions form only one object or different objects. \n",
    "\n",
    "### Thresholding \n",
    "\n",
    "The simplest way of doing this is to use a manually selected threshold, where an intensity value is defined as a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf94dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "nuclei = image.data[0,3,0,:,:] # the object we want to segment and set as markers of our final ROI\n",
    "\n",
    "threshold = 6  # change threshold value here to see what happens to the mask that is being displayed below\n",
    "mask = nuclei >= threshold  \n",
    "\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.title('Thresholded image')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff5bde0",
   "metadata": {},
   "source": [
    "Lets plot the contour of this mask over the image to judge the quality of the segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1732bc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "\n",
    "contours = measure.find_contours(mask)\n",
    "\n",
    "plt.imshow(nuclei)\n",
    "# For each elements of the contours\n",
    "for contour in contours:\n",
    "    plt.plot(contour[:,1], contour[:,0])\n",
    "\n",
    "plt.axis('off')\n",
    "plt.title('Contours of the segmented image')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65c9568",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "#### Exercise       \n",
    "\n",
    "You should notice that many countours are formed. This is because we generate the mask from the raw data. It is often a good practice to apply an appropriate filtering to the data before segmentation. Hence, apply a Gaussian filter of a given sigma to the nuclei data while avoiding any scaling in the data during the filtering process by setting preserve_range=True as an argument to the function. Secondly, generate the mask by segmenting the filtered nuclei data. \n",
    "\n",
    "Hint: nuclei_flt = filters.gaussian(nuclei, 6, preserve_range=True) \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341b27f5",
   "metadata": {},
   "source": [
    "### Automated thresholding segmentation \n",
    "\n",
    "If a single threshold is not suitable for a collection of images, a thresholding algorithm can be used. One example of this is Otsu's method [Otsu's method](https://en.wikipedia.org/wiki/Otsu%27s_method). More thresholding algorithms can be found in the [skimage.filters package](https://scikit-image.org/docs/stable/api/skimage.filters.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0f8957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "\n",
    "# filter the nuclei with a sigma 5\n",
    "nuclei_flt = filters.gaussian(nuclei, 5, preserve_range=True)\n",
    "\n",
    "# find the threshold value differentiating the signal from background\n",
    "threshold = filters.threshold_otsu(nuclei_flt) \n",
    "\n",
    "# define the threshold mask and close it\n",
    "nuclei_mask = nuclei_flt > threshold\n",
    "\n",
    "fig, ax = plt.subplots(1,3)\n",
    "\n",
    "ax[0].imshow(nuclei_flt)\n",
    "ax[0].set_title('Filtered image')\n",
    "ax[0].set_axis_off()\n",
    "\n",
    "ax[1].hist(nuclei.ravel(),log=True)\n",
    "ax[1].plot([threshold, threshold], [0,5e6])\n",
    "ax[1].set_title('Otsu threshold')\n",
    "ax[1].set_aspect(5)\n",
    "\n",
    "ax[2].imshow(nuclei_mask)\n",
    "ax[2].set_title('Thresholded image')\n",
    "ax[2].set_axis_off()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11c1497",
   "metadata": {},
   "source": [
    "### Post processing of binary masks\n",
    "The mask obtained after thresholding can be further processed using morphological operations.\n",
    "\n",
    "In the morphological operations, <br>\n",
    "- Erosion: removes small objects so only the big objects will remain in the image,\n",
    "- Dilation: makes small objects more visible and fills in small holes in objects,\n",
    "- Closing: a successive operation of those two operations dilation followed by an erosion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfed4ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import morphology\n",
    "from skimage import segmentation\n",
    "from skimage import measure\n",
    "from skimage import color\n",
    "\n",
    "# remove artifacts connected to image border\n",
    "only_large_objects = morphology.remove_small_objects(nuclei_mask, 10000)\n",
    "cleared = morphology.closing(only_large_objects, morphology.footprint_rectangle((20, 20)))\n",
    "cleared = segmentation.clear_border(cleared)\n",
    "\n",
    "# label image regions\n",
    "nuclei_label = measure.label(cleared)\n",
    "\n",
    "# label image to rgb \n",
    "nuclei_label_overlay = color.label2rgb(nuclei_label, image=10*nuclei, bg_label=0)\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(8,5))\n",
    "\n",
    "ax[0,0].imshow(nuclei_flt)\n",
    "ax[0,0].set_title('Filtered Nuclei channel')\n",
    "ax[0,0].set_axis_off()\n",
    "\n",
    "\n",
    "ax[0,1].imshow(nuclei_mask)\n",
    "ax[0,1].set_title('Otsu threshold')\n",
    "ax[0,1].set_axis_off()\n",
    "\n",
    "ax[0,2].imshow(only_large_objects)\n",
    "ax[0,2].set_title('Large Objects')\n",
    "ax[0,2].set_axis_off()\n",
    "\n",
    "ax[1,0].imshow(cleared)\n",
    "ax[1,0].set_title('Cleared mask')\n",
    "ax[1,0].set_axis_off()\n",
    "\n",
    "ax[1,1].imshow(nuclei_label)\n",
    "ax[1,1].set_title('Label image')\n",
    "ax[1,1].set_axis_off()\n",
    "\n",
    "ax[1,2].imshow(nuclei_label_overlay)\n",
    "ax[1,2].set_title('Mask and image overlay')\n",
    "ax[1,2].set_axis_off()\n",
    "\n",
    "contours = measure.find_contours(nuclei_label)\n",
    "for contour in contours:\n",
    "    plt.plot(contour[:,1], contour[:,0])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781d5fea",
   "metadata": {},
   "source": [
    "### Watershed-based segmentation\n",
    "The segmentation of the nuclei is pretty straightforward because they are well separated. In some cases however, the objects we want to segment overlap, making it difficult to discern the different regions. In this case, we would need to add extra step into the image segmentation in order to discern the objects. Watershed segmentation is useful for this purpose. It is generally used for separating different objects. Watershed algorithm treats pixels values as a local topography (elevation) so the goal is to follow the flow of the elevation and find the watershed lines from which the edge of each of the regions are deduced. We use this principle to extract our previously defined ROIs: the actin region in Channel-1 having the two nuclei as markers and the seeds of the segmentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600eadd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "actin  = image.data[0, 1, 0, :, :] #  the channel we want to segment \n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "axs[0].imshow(actin)\n",
    "axs[0].set_title('Actin channel')\n",
    "axs[0].set_axis_off()\n",
    "\n",
    "axs[1].imshow(nuclei)\n",
    "axs[1].set_title('Nuclei channel')\n",
    "axs[1].set_axis_off()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb1d8a0",
   "metadata": {},
   "source": [
    "#### Mask in the actin channel\n",
    "Create a mask on the actin using thresholding and morphological operations for closing and filling the mask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d261d77c",
   "metadata": {},
   "source": [
    "In the following cell, we first segment the actin channel and use the binary_fill_holes from ndimage to fill holes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7be7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage as ndi\n",
    "from skimage import filters\n",
    "\n",
    "# smoothed the image using the Gaussian filter of a given sigma\n",
    "smooth_actin = filters.gaussian(actin, sigma=90, preserve_range=True)\n",
    "print('(min, max) of the dynamic range of smooth_actin =', (np.min(smooth_actin), np.max(smooth_actin)))\n",
    "\n",
    "# find the optimal threshold\n",
    "threshold = filters.threshold_otsu(smooth_actin)\n",
    "print(\"optimal threshold:\", threshold)\n",
    "\n",
    "# define the threshold mask\n",
    "thresh_mask = smooth_actin > threshold\n",
    "\n",
    "# fill holes to form the the actin_mask without performing the closing function\n",
    "actin_mask = ndi.binary_fill_holes(thresh_mask).astype(int)\n",
    "\n",
    "fig, axs = plt.subplots(1,4, figsize=(15, 15))\n",
    "axs[0].imshow(actin)\n",
    "axs[0].set_title('Original image')\n",
    "axs[0].set_axis_off()\n",
    "\n",
    "axs[1].imshow(smooth_actin)\n",
    "axs[1].set_title('Gaussian filter')\n",
    "axs[1].set_axis_off()\n",
    "\n",
    "axs[2].imshow(thresh_mask)\n",
    "axs[2].set_title('Thresholded image')\n",
    "axs[2].set_axis_off()\n",
    "\n",
    "axs[3].imshow(actin_mask)\n",
    "axs[3].set_title('Fill holes')\n",
    "axs[3].set_axis_off()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db447c75",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "#### Exercise       \n",
    "\n",
    "In the previous cell, play with the sigma value of the filters.gaussian to observe the effect on the segmentation.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39028a22",
   "metadata": {},
   "source": [
    "#### Distance transform and watershed\n",
    "The next step will consists of computing the distance transform of the actin mask. Observe how the value of the distance inside the regions change with the spatial coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc5244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage as ndi\n",
    "distance = ndi.distance_transform_edt(actin_mask) \n",
    "\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "\n",
    "ax[0].imshow(actin_mask)\n",
    "ax[0].set_title('Mask')\n",
    "ax[0].set_axis_off()\n",
    "\n",
    "im = ax[1].imshow(distance, cmap='jet')\n",
    "ax[1].set_title('Distance transform')\n",
    "ax[1].set_axis_off()\n",
    "\n",
    "# insert the colorbar \n",
    "ax[2].set_position([0.64, 0.4, 0.025, 0.2])\n",
    "\n",
    "fig.colorbar(im, cax=ax[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6099362",
   "metadata": {},
   "source": [
    "Now we set the nuclei we segmented before as the markers or seeds of the segmentations. We use the markers to label the segmented regions in the actin region. \n",
    "After, we watershed the negative inverse of the distance transform of the actin using the defined markers and within the mask delimited by the actin. The negative inverse of the distance is used in the watershed function instead of the distance because the goal is to have the objects region as valleys not peak.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14150b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import segmentation\n",
    "\n",
    "cell_label = segmentation.watershed(-distance, markers = nuclei_label, mask = actin_mask)\n",
    "\n",
    "fig, ax = plt.subplots(1,4, figsize=(15, 15))\n",
    "\n",
    "# create a RGB composite image to display the two channels (normalize channel in between 0 and 1)\n",
    "rgb = np.stack([actin.astype(float) / actin.max(), \n",
    "                np.zeros(actin.shape), \n",
    "                nuclei.astype(float) / nuclei.max()], axis=2)\n",
    "\n",
    "ax[0].imshow(rgb)\n",
    "ax[0].set_axis_off()\n",
    "ax[0].set_title('Actin and nuclei')\n",
    "\n",
    "ax[1].imshow(distance, cmap='jet')\n",
    "ax[1].set_title('Distance')\n",
    "ax[1].set_axis_off()\n",
    "\n",
    "ax[2].imshow(nuclei_label)\n",
    "ax[2].set_title('Markers (seeds of segmentation)')\n",
    "ax[2].set_axis_off()\n",
    "\n",
    "ax[3].imshow(cell_label)\n",
    "ax[3].set_title('Segmented ROIs')\n",
    "ax[3].set_axis_off()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece38105",
   "metadata": {},
   "source": [
    "## Region properties\n",
    "\n",
    "To measure information within the ROI masks that we have previously segmented, we use the regionprops function. It allows us to define a list of geometrical and intensity properties which can be measured in the images. \n",
    "\n",
    "This is a selection of useful properties supported by regionprops:\n",
    "  - area\n",
    "  - bbox\n",
    "  - bbox_area\n",
    "  - centroid\n",
    "  - coords\n",
    "  - equivalent_diameter\n",
    "  - label\n",
    "  - major_axis_length\n",
    "  - max_intensity\n",
    "  - mean_intensity\n",
    "  - min_intensity\n",
    "  - minor_axis_length\n",
    "  - slice\n",
    "  - solidity\n",
    "  - eccentricity\n",
    "  - orientation\n",
    "  - perimeter\n",
    "\n",
    "### Maximum Intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7907bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from skimage import measure\n",
    "\n",
    "\n",
    "peroxisome = image.data[0, 2, 0, :, :]\n",
    "\n",
    "max_intensity_table = measure.regionprops_table(cell_label, peroxisome, properties=('label', 'intensity_max'))\n",
    "max_intensity_dataframe = pd.DataFrame(max_intensity_table)\n",
    "\n",
    "max_intensity_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44959734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from skimage import measure\n",
    "\n",
    "peroxisome = image.data[0, 2, 0, :, :]\n",
    "\n",
    "peroxisome_props = measure.regionprops(cell_label, peroxisome)\n",
    "actin_props = measure.regionprops(cell_label, actin)\n",
    "\n",
    "# Get the list of labels from the regions properties\n",
    "labels = [p.label for p in peroxisome_props]\n",
    "\n",
    "# Get the maximum intensity for the properties\n",
    "peroxisome_max_intensity = [p.intensity_max for p in peroxisome_props]\n",
    "actin_max_intensity = [p.intensity_max for p in actin_props]\n",
    "\n",
    "# Gather the results in a data frame (table)\n",
    "max_intensity_dataframe = pd.DataFrame({\n",
    "    'Region label': labels, \n",
    "    'Peroxisome [ch2] maximum intensity': peroxisome_max_intensity,\n",
    "    'Actin [ch1] maximum intensity': actin_max_intensity})\n",
    "\n",
    "max_intensity_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d63bf82",
   "metadata": {},
   "source": [
    "### Defining a custom measurement to count the number of peroxisome spots per cell\n",
    "\n",
    "A custom function needs to be defined to count the number of peroxisome spots or blobs for each cell ROI as the regionprops function cannot directly do it. To achieve this goal, we can follow the following steps:\n",
    "\n",
    "1. Detect the blobs using the blob_log spot detector\n",
    "2. Convert the blobs coordinates into a label point image\n",
    "3. Define a function that counts the blobs labels per ROI\n",
    "4. Add the custom function into the extra_properties of regionprops_table\n",
    "5. Convert the result into a pandas dataframe\n",
    "6. Merge the dataframe with the previous table of maximal intensity\n",
    "7. Inspect final result by visualizing the different steps in napari\n",
    "8. Save the final result in a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a6ef22",
   "metadata": {},
   "source": [
    "The Laplacian of Gaussian (LoG) is an accurate but slower approach for blob detection in skimage. We will cover three important parameters here:\n",
    "\n",
    "- min_sigma: the minimum standard deviation for Gaussian kernel.\n",
    "- max_sigma: the maximum standard deviation for Gaussian kernel.\n",
    "- threshold: the absolute lower bound for scale space maxima. Local maxima smaller than threshold are ignored.\n",
    "\n",
    "Further reading: https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.blob_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e9d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature\n",
    "\n",
    "# detect blobs\n",
    "blobs = feature.blob_log(peroxisome, min_sigma=2, max_sigma=10, threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1686e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display blobs\n",
    "plt.imshow(peroxisome, vmax=peroxisome.max()/10)\n",
    "plt.plot(blobs[:,1], blobs[:,0], 'o', ms=5, fillstyle='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a0e74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.util import label_points\n",
    "\n",
    "# convert blobs coordinates into a label point image\n",
    "peroxisome_label = label_points(blobs[:, 0:2], peroxisome.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caf9b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_blobs(mask, blob_label):\n",
    "    '''Count the number of blobs in a mask\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mask : binary image\n",
    "    blob_label: image labelled with the blob ids\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    number of blobs per mask\n",
    "    '''\n",
    "    count = len(np.unique(blob_label[mask])) - 1 # -1 because the label 0 is reserved for the backgroun\n",
    "    return count\n",
    "\n",
    "number_peroxisome = measure.regionprops_table(cell_label, peroxisome_label, \n",
    "                                 properties = ('label',), \n",
    "                                 extra_properties = (count_blobs,))\n",
    "\n",
    "number_peroxisome_dataframe = pd.DataFrame(number_peroxisome)\n",
    "\n",
    "# rename the 'label' column to 'Region label'\n",
    "number_peroxisome_dataframe = number_peroxisome_dataframe.rename(columns={\"label\": 'Region label'})\n",
    "\n",
    "number_peroxisome_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feb7cf3",
   "metadata": {},
   "source": [
    "Merge the two dataframe number_peroxisome_dataframe and max_intensity_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a436f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.merge(max_intensity_dataframe, number_peroxisome_dataframe, how='outer', on='Region label')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2432a66f",
   "metadata": {},
   "source": [
    "## Visualize in napari"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f02734",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "       \n",
    "#### Exercise \n",
    "\n",
    "Display in different napari layers the following:\n",
    "\n",
    "1. the raw data with channel_names = ['mitochondria', 'actin', 'peroxisome', 'nuclei'] and appropriate contrast_limits\n",
    "2. the cell_label in a label layer\n",
    "3. the points generated in the 'blobs' variable with opacity equal to 0.5\n",
    "4. the peroxisome_label as an image layer with a 'green' colormap and 'additive' blending \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac800f5",
   "metadata": {},
   "source": [
    "## Save result\n",
    "Export the result stored in the panda dataframe into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12ad5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('peroxisome_count.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dynamicIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
