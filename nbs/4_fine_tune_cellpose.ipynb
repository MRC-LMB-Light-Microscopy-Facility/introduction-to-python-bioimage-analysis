{
   "cells": [
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "<table>\n",
            "  <tr>\n",
            "    <td><p style=\"font-size:45px; color: #55BBD2\">Analysis of light microscopy images in Python</p></td>\n",
            "    <td><img src=\"../ressources/lmb_logo.svg\" alt=\"LMB Logo\" width=\"500\" height=\"600\" align=\"right\"></td>\n",
            "  </tr>\n",
            "</table>\n",
            "<table>\n",
            "  <tr>\n",
            "    <td><p style=\"font-size:15px; color: #55BBD2\">Version: September 2025</p></td>\n",
            "  </tr>\n",
            "</table>"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Part 4 Fine-tune CellPose model in the GUI\n",
            "\n",
            "<b>Live Demo:</b> Human-in-the-loop (HITL) in [Cellpose 2.0](https://www.nature.com/articles/s41592-022-01663-4) allows users to improve segmentation by correcting masks and retraining the model directly in the GUI. It's useful when pretrained models underperform or when a custom model is needed. With just a few manual corrections, users can adapt Cellpose to their data without coding, enabling fast and effective segmentation refinement.\n",
            "\n",
            "<b>Dataset 2:</b> Human_in_the_loop folder\n",
            "\n",
            "<img src=\"../ressources/data3.png\" alt=\"drawing\" width=\"400\"/>\n",
            "\n",
            "<b>Credit:</b> [LIVECell dataset](https://sartorius-research.github.io/LIVECell/) © 2021 Ulman, C., Moen, E., Bannon, D. et al. Licensed under CC BY-NC 4.0. Ulman, C., Moen, E., Bannon, D. et al. An annotated dataset for live-cell imaging. Nature Methods 18, 963–965 (2021). [https://doi.org/10.1038/s41592-021-01249-6]\n",
            "\n",
            "<b>Workflow:</b>\n",
            "\n",
            "<img src=\"../ressources/hitl.png\" alt=\"drawing\" width=\"800\"/>\n",
            "\n",
            "<b>Objectives:</b>\n",
            "- Launch CellPose GUI from notebook (!) \n",
            "- Retrain custom models using the CellPose GUI \n",
            "- Use the custom models with Python"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Launch Cellpose GUI from Windows"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "! cellpose"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Procedures\n",
            "\n",
            "1. Load & Configure\n",
            "- Open one representative image.\n",
            "- Pick a pretrained model (default **cyto3** or from **dataset-specific models**).\n",
            "- Set **Channels** (main + optional aux) to match your data.\n",
            "- Set **Diameter**.\n",
            "\n",
            "2. First Pass Segmentation\n",
            "- Click **Run** to generate masks.\n",
            "- Inspect overlays (toggle labels on/off; use mouse wheel to zoom in on tricky regions).\n",
            "\n",
            "3. Human Corrections (the “loop”)\n",
            "- Add missing cells with rigth click and draw.\n",
            "- Remove false positives with ctrl + click or **click-select** + **done**.\n",
            "- This creates training-ready mask files matching the image names in the same folder.\n",
            "\n",
            "4. Train a Custom Model\n",
            "- Go to the **Models** tab:\n",
            "  - **Train new model with image+mask in the folder**\n",
            "  - Select your corrected images and masks folder.\n",
            "  - Choose a pre-trained model (e.g., **cyto2_cp3**) and a short training run (default value usually works fine).\n",
            "  - Start training \n",
            "  - Cellpose will save a model under `models/` in the same folder.\n",
            "  - CellPose will automatically apply the custom model to the next image in the same folder\n",
            "\n",
            "5. Apply the New Model\n",
            "- Switch to your newly trained model in the GUI from **Other models**.\n",
            "- Test it on the test image.\n",
            "- Spot‑check results; repeat corrections and training if needed.\n",
            "\n",
            "Tips\n",
            "- Start with **3–5 diverse images** for your first correction cycle.\n",
            "- Keep early training **short** for fast iteration.\n",
            "- Revisit channel/diameter settings if segmentation errors persist.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "<div class=\"alert alert-success\">\n",
            "\n",
            "#### Exercise\n",
            "\n",
            "Use your custom trained Cellpose model to segment new images with Python. <br>\n",
            "Hint: <br>\n",
            "1. Load the test image with `image_path = '..\\data\\test\\A172_Phase_A7_2_00d20h00m_4.tif'`\n",
            "2. Give the path to your custom model with `model_path = '..\\models\\my_model'`<br>\n",
            "3. Load the model with `model_retrain = models.CellposeModel()`<br>\n",
            "4. Run `model_retrain.eval()` on your test image<br>\n",
            "5. Display the results using matplotlib\n",
            "\n",
            "</div>"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "cellpose_pytrain3",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.18"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 4
}
