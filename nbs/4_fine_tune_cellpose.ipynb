{
   "cells": [
      {
         "attachments": {},
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "<table>\n",
            "  <tr>\n",
            "    <td><p style=\"font-size:45px; color: #55BBD2\">Analysis of light microscopy images in Python</p></td>\n",
            "    <td><img src=\"../ressources/lmb_logo.svg\" alt=\"LMB Logo\" width=\"500\" height=\"600\" align=\"right\"></td>\n",
            "  </tr>\n",
            "</table>\n",
            "<table>\n",
            "  <tr>\n",
            "    <td><p style=\"font-size:15px; color: #55BBD2\">Version: September 2025</p></td>\n",
            "  </tr>\n",
            "</table>"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Part 4 Fine-tune CellPose model in the GUI\n",
            "\n",
            "<b>Live Demo:</b> Human-in-the-loop (HITL) in [Cellpose 2.0](https://www.nature.com/articles/s41592-022-01663-4) allows users to improve segmentation by correcting masks and retraining the model directly in the GUI. It's useful when pretrained models underperform or when a custom model is needed. With just a few manual corrections, users can adapt Cellpose to their data without coding, enabling fast and effective segmentation refinement.\n",
            "\n",
            "<b>Dataset 2:</b> Human_in_the_loop folder\n",
            "\n",
            "<img src=\"../ressources/data3.png\" alt=\"drawing\" width=\"400\"/>\n",
            "\n",
            "<b>Credit:</b> [LIVECell dataset](https://sartorius-research.github.io/LIVECell/) © 2021 Ulman, C., Moen, E., Bannon, D. et al. Licensed under CC BY-NC 4.0. Ulman, C., Moen, E., Bannon, D. et al. An annotated dataset for live-cell imaging. Nature Methods 18, 963–965 (2021). [https://doi.org/10.1038/s41592-021-01249-6]\n",
            "\n",
            "<b>Workflow:</b>\n",
            "\n",
            "<img src=\"../ressources/hitl.png\" alt=\"drawing\" width=\"800\"/>\n",
            "\n",
            "<b>Objectives:</b>\n",
            "- Launch CellPose GUI from notebook (!) \n",
            "- Retrain custom models using the CellPose GUI \n",
            "- Use the custom models with Python"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Launch Cellpose GUI from Mac; go to the next cell when using Windows"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "2025-09-25 15:54:32,088 [INFO] WRITING LOG OUTPUT TO /Users/qwu/.cellpose/run.log\n",
                  "2025-09-25 15:54:32,088 [INFO] \n",
                  "cellpose version: \t3.1.1.2 \n",
                  "platform:       \tdarwin \n",
                  "python version: \t3.10.18 \n",
                  "torch version:  \t2.8.0\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "usage: cellpose [-h] [--version] [--verbose] [--Zstack] [--use_gpu]\n",
                  "                [--gpu_device GPU_DEVICE] [--check_mkl] [--dir DIR]\n",
                  "                [--image_path IMAGE_PATH] [--look_one_level_down]\n",
                  "                [--img_filter IMG_FILTER] [--channel_axis CHANNEL_AXIS]\n",
                  "                [--z_axis Z_AXIS] [--chan CHAN] [--chan2 CHAN2] [--invert]\n",
                  "                [--all_channels] [--pretrained_model PRETRAINED_MODEL]\n",
                  "                [--restore_type RESTORE_TYPE] [--chan2_restore]\n",
                  "                [--add_model ADD_MODEL] [--transformer]\n",
                  "                [--pretrained_model_ortho PRETRAINED_MODEL_ORTHO]\n",
                  "                [--no_resample] [--no_interp] [--no_norm]\n",
                  "                [--norm_percentile VALUE1 VALUE2] [--do_3D]\n",
                  "                [--diameter DIAMETER] [--stitch_threshold STITCH_THRESHOLD]\n",
                  "                [--min_size MIN_SIZE] [--flow3D_smooth FLOW3D_SMOOTH]\n",
                  "                [--flow_threshold FLOW_THRESHOLD]\n",
                  "                [--cellprob_threshold CELLPROB_THRESHOLD] [--niter NITER]\n",
                  "                [--anisotropy ANISOTROPY] [--exclude_on_edges] [--augment]\n",
                  "                [--save_png] [--save_tif] [--output_name OUTPUT_NAME]\n",
                  "                [--no_npy] [--savedir SAVEDIR] [--dir_above] [--in_folders]\n",
                  "                [--save_flows] [--save_outlines] [--save_rois] [--save_txt]\n",
                  "                [--save_mpl] [--train] [--train_size] [--test_dir TEST_DIR]\n",
                  "                [--file_list FILE_LIST] [--mask_filter MASK_FILTER]\n",
                  "                [--diam_mean DIAM_MEAN] [--learning_rate LEARNING_RATE]\n",
                  "                [--weight_decay WEIGHT_DECAY] [--n_epochs N_EPOCHS]\n",
                  "                [--batch_size BATCH_SIZE] [--nimg_per_epoch NIMG_PER_EPOCH]\n",
                  "                [--nimg_test_per_epoch NIMG_TEST_PER_EPOCH]\n",
                  "                [--min_train_masks MIN_TRAIN_MASKS] [--SGD SGD]\n",
                  "                [--save_every SAVE_EVERY] [--model_name_out MODEL_NAME_OUT]\n",
                  "cellpose: error: unrecognized arguments: gui\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "2025-09-25 15:54:34,521 [INFO] ** TORCH MPS version installed and working. **\n",
                  "\u001b[0m"
               ]
            }
         ],
         "source": [
            "def launch_cellpose_gui():\n",
            "    import os\n",
            "    import subprocess\n",
            "\n",
            "    os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
            "    subprocess.Popen([\"cellpose\", \"gui\"])\n",
            "\n",
            "# Run it\n",
            "launch_cellpose_gui()\n",
            "\n",
            "! python3 -m cellpose"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Launch Cellpose GUI from Windows"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "! cellpose"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## Procedures\n",
            "\n",
            "1. Load & Configure\n",
            "- Open one representative image.\n",
            "- Pick a pretrained model (default **cyto3** or from **dataset-specific models**).\n",
            "- Set **Channels** (main + optional aux) to match your data.\n",
            "- Set **Diameter**.\n",
            "\n",
            "2. First Pass Segmentation\n",
            "- Click **Run** to generate masks.\n",
            "- Inspect overlays (toggle labels on/off; use mouse wheel to zoom in on tricky regions).\n",
            "\n",
            "3. Human Corrections (the “loop”)\n",
            "- Add missing cells with rigth click and draw.\n",
            "- Remove false positives with ctrl + click or **click-select** + **done**.\n",
            "- This creates training-ready mask files matching the image names in the same folder.\n",
            "\n",
            "4. Train a Custom Model\n",
            "- Go to the **Models** tab:\n",
            "  - **Train new model with image+mask in the folder**\n",
            "  - Select your corrected images and masks folder.\n",
            "  - Choose a pre-trained model (e.g., **cyto3**) and a short training run (default value usually works fine).\n",
            "  - Start training \n",
            "  - Cellpose will save a model under `models/` in the same folder.\n",
            "  - CellPose will automatically apply the custom model to the next image in the same folder\n",
            "\n",
            "5. Apply the New Model\n",
            "- Switch to your newly trained model in the GUI **Other models**.\n",
            "- Test it on the test image.\n",
            "- Spot‑check results; repeat corrections and training if needed.\n",
            "\n",
            "Tips\n",
            "- Start with **3–5 diverse images** for your first correction cycle.\n",
            "- Keep early training **short** for fast iteration.\n",
            "- Revisit channel/diameter settings if segmentation errors persist.\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "<div class=\"alert alert-success\">\n",
            "\n",
            "#### Exercise\n",
            "\n",
            "Use your custom trained Cellpose model to segment new images with Python. <br>\n",
            "Hint: <br>\n",
            "1. Load the test image with `image_path = '..\\data\\test\\A172_Phase_A7_2_00d20h00m_4.tif'`\n",
            "2. Give the path to your custom model with `model_path = '..\\models\\my_model'`<br>\n",
            "3. Load the model with `model_retrain = models.CellposeModel()`<br>\n",
            "4. Run `model_retrain.eval()` on your test image<br>\n",
            "5. Display the results using matplotlib\n",
            "\n",
            "</div>"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "cellpose_pytrain3",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.18"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 4
}
